{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "data = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8008"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove entries with NaN values for columns taken as features\n",
    "data = data[data['publication_year'].notna()]\n",
    "data = data[data['authors'].notna()]\n",
    "data = data[data['num_pages'].notna()]\n",
    "data = data[data['genre'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5347"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine age of book as (2020 - publication_year)\n",
    "data['age'] = [(2020 - int(x)) for x in data['publication_year']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>age</th>\n",
       "      <th>genre</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'author_id': '3041852', 'role': ''}]</td>\n",
       "      <td>162.0</td>\n",
       "      <td>14</td>\n",
       "      <td>history</td>\n",
       "      <td>4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'author_id': '37778', 'role': ''}]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>11</td>\n",
       "      <td>history</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'author_id': '137561', 'role': ''}]</td>\n",
       "      <td>288.0</td>\n",
       "      <td>14</td>\n",
       "      <td>history</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'author_id': '51229', 'role': ''}, {'author_...</td>\n",
       "      <td>332.0</td>\n",
       "      <td>8</td>\n",
       "      <td>history</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'author_id': '337108', 'role': ''}, {'author...</td>\n",
       "      <td>659.0</td>\n",
       "      <td>14</td>\n",
       "      <td>history</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>[{'author_id': '8108129', 'role': ''}]</td>\n",
       "      <td>270.0</td>\n",
       "      <td>6</td>\n",
       "      <td>young adult</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>[{'author_id': '614210', 'role': ''}]</td>\n",
       "      <td>199.0</td>\n",
       "      <td>6</td>\n",
       "      <td>young adult</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>[{'author_id': '11664', 'role': ''}]</td>\n",
       "      <td>208.0</td>\n",
       "      <td>7</td>\n",
       "      <td>young adult</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>[{'author_id': '2987125', 'role': ''}, {'autho...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>7</td>\n",
       "      <td>young adult</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>[{'author_id': '2885318', 'role': ''}]</td>\n",
       "      <td>454.0</td>\n",
       "      <td>5</td>\n",
       "      <td>young adult</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5347 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                authors  num_pages  age  \\\n",
       "0                [{'author_id': '3041852', 'role': ''}]      162.0   14   \n",
       "1                  [{'author_id': '37778', 'role': ''}]      400.0   11   \n",
       "2                 [{'author_id': '137561', 'role': ''}]      288.0   14   \n",
       "4     [{'author_id': '51229', 'role': ''}, {'author_...      332.0    8   \n",
       "6     [{'author_id': '337108', 'role': ''}, {'author...      659.0   14   \n",
       "...                                                 ...        ...  ...   \n",
       "8000             [{'author_id': '8108129', 'role': ''}]      270.0    6   \n",
       "8002              [{'author_id': '614210', 'role': ''}]      199.0    6   \n",
       "8003               [{'author_id': '11664', 'role': ''}]      208.0    7   \n",
       "8005  [{'author_id': '2987125', 'role': ''}, {'autho...      288.0    7   \n",
       "8006             [{'author_id': '2885318', 'role': ''}]      454.0    5   \n",
       "\n",
       "            genre  average_rating  \n",
       "0         history            4.13  \n",
       "1         history            3.93  \n",
       "2         history            3.98  \n",
       "4         history            4.28  \n",
       "6         history            3.54  \n",
       "...           ...             ...  \n",
       "8000  young adult            3.84  \n",
       "8002  young adult            3.79  \n",
       "8003  young adult            4.10  \n",
       "8005  young adult            4.15  \n",
       "8006  young adult            3.42  \n",
       "\n",
       "[5347 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select columns title, authors, num_pages, age, genre, and average_rating as data\n",
    "data = data[['authors', 'num_pages', 'age', 'genre', 'average_rating']]\n",
    "\n",
    "#drop null values\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5347 entries, 0 to 8006\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   authors         5347 non-null   object \n",
      " 1   num_pages       5347 non-null   float64\n",
      " 2   age             5347 non-null   int64  \n",
      " 3   genre           5347 non-null   object \n",
      " 4   average_rating  5347 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 250.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#look at the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f992616a9b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find no. of pages outliers\n",
    "# sns.boxplot(x=data['num_pages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from no. of pages \n",
    "data = data.drop(data.index[data['num_pages'] >= 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "#Transforming textual features into numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode authors column\n",
    "data['authors'] = le.fit_transform(data['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode genre column\n",
    "data['genre'] = le.fit_transform(data['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5331 entries, 0 to 8006\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   authors         5331 non-null   int32  \n",
      " 1   num_pages       5331 non-null   float64\n",
      " 2   age             5331 non-null   int64  \n",
      " 3   genre           5331 non-null   int32  \n",
      " 4   average_rating  5331 non-null   float64\n",
      "dtypes: float64(2), int32(2), int64(1)\n",
      "memory usage: 208.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for authors and genre\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "max_value_authors = data['authors'].max()\n",
    "max_value_genre = data['genre'].max()\n",
    "authors_encoder = LabelBinarizer()\n",
    "genre_encoder = LabelBinarizer()\n",
    "authors_encoder.fit(data['authors'])\n",
    "genre_encoder.fit(data['genre'])\n",
    "transformed_authors = authors_encoder.transform(data['authors'])\n",
    "transformed_genres = genre_encoder.transform(data['genre'])\n",
    "onehot_authors_df = pd.DataFrame(transformed_authors)\n",
    "onehot_genres_df = pd.DataFrame(transformed_genres)\n",
    "data = pd.concat([data,onehot_authors_df,onehot_genres_df],axis=1).drop(['authors','genre'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into attributes and labels\n",
    "X = data.drop(['average_rating'], axis = 1)\n",
    "y = data['average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 80% of the data to the training set and 20% of the data to test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 10)\n",
    "X_train = torch.tensor(X_train.values).float()\n",
    "X_test = torch.tensor(X_test.values).float()\n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "y_train = torch.unsqueeze(y_train,1)\n",
    "y_test = torch.tensor(y_test.values).float()\n",
    "y_test = torch.unsqueeze(y_test,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1311, 0.0085, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2787, 0.0085, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.0287, 0.0030, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0410, 0.0050, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3443, 0.0095, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.1639, 0.0140, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# remove nan values for page number,age,authors\n",
    "X_train_mask = X_train[:,0].eq(X_train[:,0]) # mask for nan values\n",
    "X_train_mask = X_train_mask & X_train[:,1].eq(X_train[:,1]) # mask for nan values\n",
    "X_train_mask = X_train_mask & X_train[:,2].eq(X_train[:,2]) # mask for nan values\n",
    "\n",
    "X_test_mask = X_test[:,0].eq(X_test[:,0]) # mask for nan values\n",
    "X_test_mask = X_test_mask & X_test[:,1].eq(X_test[:,1]) # mask for nan values\n",
    "X_test_mask = X_test_mask & X_test[:,2].eq(X_test[:,2]) # mask for nan values\n",
    "\n",
    "X_train = X_train[X_train_mask,:]\n",
    "y_train = y_train[X_train_mask,:]\n",
    "X_test = X_test[X_test_mask,:]\n",
    "y_test = y_test[X_test_mask,:]\n",
    "\n",
    "#normalize pages, age\n",
    "pages_max = torch.max(X_train[:,0])\n",
    "age_max = torch.max(X_train[:,1])\n",
    "X_train[:,0] = X_train[:,0] / pages_max\n",
    "X_train[:,1] = X_train[:,1] / age_max\n",
    "\n",
    "X_test[:,0] = X_test[:,0] / pages_max\n",
    "X_test[:,1] = X_test[:,1] / age_max\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.64</td>\n",
       "      <td>3.926094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.24</td>\n",
       "      <td>3.944888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.08</td>\n",
       "      <td>3.892507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.21</td>\n",
       "      <td>3.871408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.99</td>\n",
       "      <td>3.930625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.90</td>\n",
       "      <td>3.935830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.04</td>\n",
       "      <td>3.924351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.32</td>\n",
       "      <td>3.883338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.12</td>\n",
       "      <td>3.874602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.17</td>\n",
       "      <td>3.855039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0    3.64   3.926094\n",
       "1    4.24   3.944888\n",
       "2    4.08   3.892507\n",
       "3    4.21   3.871408\n",
       "4    3.99   3.930625\n",
       "5    3.90   3.935830\n",
       "6    4.04   3.924351\n",
       "7    4.32   3.883338\n",
       "8    4.12   3.874602\n",
       "9    4.17   3.855039"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame({'Actual': y_test.tolist(), 'Predicted': predictions.tolist()}).head(25)\n",
    "pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9926720710>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the above comparison result\n",
    "pred.plot(kind='bar', figsize=(13, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.2776167878627979\n",
      "MSE: 0.12774518548521124\n",
      "RMSE: 0.35741458488037564\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance of the algorithm\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    self.loss_criterion = nn.MSELoss()\n",
    "    \n",
    "    self.fc_layers = nn.Sequential(\n",
    "          nn.Linear(4395,300),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(300,100),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(100,1)\n",
    "    )\n",
    "    \n",
    "\n",
    "  def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "    '''\n",
    "    Perform the forward pass with the net\n",
    "\n",
    "    '''\n",
    "    model_output = self.fc_layers(x)\n",
    "    return model_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss :14.87890911102295 Test Loss:14.838125228881836\n",
      "Epoch 2 Training Loss :14.133030891418457 Test Loss:14.093783378601074\n",
      "Epoch 3 Training Loss :13.42531967163086 Test Loss:13.387672424316406\n",
      "Epoch 4 Training Loss :12.747092247009277 Test Loss:12.710983276367188\n",
      "Epoch 5 Training Loss :12.093786239624023 Test Loss:12.059233665466309\n",
      "Epoch 6 Training Loss :11.463861465454102 Test Loss:11.430787086486816\n",
      "Epoch 7 Training Loss :10.85459041595459 Test Loss:10.822893142700195\n",
      "Epoch 8 Training Loss :10.263143539428711 Test Loss:10.232677459716797\n",
      "Epoch 9 Training Loss :9.686277389526367 Test Loss:9.65700912475586\n",
      "Epoch 10 Training Loss :9.121350288391113 Test Loss:9.093316078186035\n",
      "Epoch 11 Training Loss :8.56667709350586 Test Loss:8.539867401123047\n",
      "Epoch 12 Training Loss :8.021400451660156 Test Loss:7.995820999145508\n",
      "Epoch 13 Training Loss :7.485214710235596 Test Loss:7.460879802703857\n",
      "Epoch 14 Training Loss :6.958240985870361 Test Loss:6.935189247131348\n",
      "Epoch 15 Training Loss :6.440990447998047 Test Loss:6.419239521026611\n",
      "Epoch 16 Training Loss :5.934330463409424 Test Loss:5.913924217224121\n",
      "Epoch 17 Training Loss :5.439388751983643 Test Loss:5.420370101928711\n",
      "Epoch 18 Training Loss :4.957612037658691 Test Loss:4.9399895668029785\n",
      "Epoch 19 Training Loss :4.490785121917725 Test Loss:4.474572658538818\n",
      "Epoch 20 Training Loss :4.040985584259033 Test Loss:4.026227951049805\n",
      "Epoch 21 Training Loss :3.610515594482422 Test Loss:3.5972604751586914\n",
      "Epoch 22 Training Loss :3.201723337173462 Test Loss:3.1899919509887695\n",
      "Epoch 23 Training Loss :2.8169174194335938 Test Loss:2.8067378997802734\n",
      "Epoch 24 Training Loss :2.4582486152648926 Test Loss:2.4496331214904785\n",
      "Epoch 25 Training Loss :2.1275384426116943 Test Loss:2.120497226715088\n",
      "Epoch 26 Training Loss :1.8261933326721191 Test Loss:1.8207101821899414\n",
      "Epoch 27 Training Loss :1.5550788640975952 Test Loss:1.5511280298233032\n",
      "Epoch 28 Training Loss :1.31439208984375 Test Loss:1.311938762664795\n",
      "Epoch 29 Training Loss :1.1036489009857178 Test Loss:1.1026439666748047\n",
      "Epoch 30 Training Loss :0.9217151999473572 Test Loss:0.9221071600914001\n",
      "Epoch 31 Training Loss :0.7668874263763428 Test Loss:0.7686042189598083\n",
      "Epoch 32 Training Loss :0.6369970440864563 Test Loss:0.6399655938148499\n",
      "Epoch 33 Training Loss :0.5295544862747192 Test Loss:0.5337001085281372\n",
      "Epoch 34 Training Loss :0.4419000446796417 Test Loss:0.4471389353275299\n",
      "Epoch 35 Training Loss :0.37133142352104187 Test Loss:0.37758058309555054\n",
      "Epoch 36 Training Loss :0.3152369558811188 Test Loss:0.32241013646125793\n",
      "Epoch 37 Training Loss :0.27118179202079773 Test Loss:0.2791978716850281\n",
      "Epoch 38 Training Loss :0.23696862161159515 Test Loss:0.24574324488639832\n",
      "Epoch 39 Training Loss :0.21067039668560028 Test Loss:0.22012276947498322\n",
      "Epoch 40 Training Loss :0.19064320623874664 Test Loss:0.20069435238838196\n",
      "Epoch 41 Training Loss :0.17551742494106293 Test Loss:0.1860942840576172\n",
      "Epoch 42 Training Loss :0.16417771577835083 Test Loss:0.1752140074968338\n",
      "Epoch 43 Training Loss :0.15573124587535858 Test Loss:0.1671672910451889\n",
      "Epoch 44 Training Loss :0.1494753211736679 Test Loss:0.1612580120563507\n",
      "Epoch 45 Training Loss :0.1448645144701004 Test Loss:0.15694659948349\n",
      "Epoch 46 Training Loss :0.14148050546646118 Test Loss:0.15382020175457\n",
      "Epoch 47 Training Loss :0.1390056610107422 Test Loss:0.15156632661819458\n",
      "Epoch 48 Training Loss :0.1372009664773941 Test Loss:0.14995068311691284\n",
      "Epoch 49 Training Loss :0.13588795065879822 Test Loss:0.14879906177520752\n",
      "Epoch 50 Training Loss :0.13493436574935913 Test Loss:0.1479828953742981\n",
      "Epoch 51 Training Loss :0.13424260914325714 Test Loss:0.1474078744649887\n",
      "Epoch 52 Training Loss :0.13374093174934387 Test Loss:0.14700530469417572\n",
      "Epoch 53 Training Loss :0.1333770453929901 Test Loss:0.14672523736953735\n",
      "Epoch 54 Training Loss :0.13311271369457245 Test Loss:0.1465318351984024\n",
      "Epoch 55 Training Loss :0.1329202502965927 Test Loss:0.14639921486377716\n",
      "Epoch 56 Training Loss :0.13277959823608398 Test Loss:0.14630894362926483\n",
      "Epoch 57 Training Loss :0.13267619907855988 Test Loss:0.14624790847301483\n",
      "Epoch 58 Training Loss :0.1325996071100235 Test Loss:0.1462068408727646\n",
      "Epoch 59 Training Loss :0.13254226744174957 Test Loss:0.14617925882339478\n",
      "Epoch 60 Training Loss :0.13249875605106354 Test Loss:0.1461605727672577\n",
      "Epoch 61 Training Loss :0.1324651688337326 Test Loss:0.14614763855934143\n",
      "Epoch 62 Training Loss :0.13243870437145233 Test Loss:0.1461382955312729\n",
      "Epoch 63 Training Loss :0.13241733610630035 Test Loss:0.14613103866577148\n",
      "Epoch 64 Training Loss :0.13239963352680206 Test Loss:0.146124929189682\n",
      "Epoch 65 Training Loss :0.13238456845283508 Test Loss:0.14611934125423431\n",
      "Epoch 66 Training Loss :0.13237139582633972 Test Loss:0.1461137980222702\n",
      "Epoch 67 Training Loss :0.132359579205513 Test Loss:0.14610810577869415\n",
      "Epoch 68 Training Loss :0.13234876096248627 Test Loss:0.14610208570957184\n",
      "Epoch 69 Training Loss :0.13233862817287445 Test Loss:0.14609570801258087\n",
      "Epoch 70 Training Loss :0.1323290318250656 Test Loss:0.14608892798423767\n",
      "Epoch 71 Training Loss :0.1323198527097702 Test Loss:0.14608173072338104\n",
      "Epoch 72 Training Loss :0.1323109120130539 Test Loss:0.14607419073581696\n",
      "Epoch 73 Training Loss :0.1323021799325943 Test Loss:0.14606629312038422\n",
      "Epoch 74 Training Loss :0.13229361176490784 Test Loss:0.1460580974817276\n",
      "Epoch 75 Training Loss :0.13228517770767212 Test Loss:0.1460495889186859\n",
      "Epoch 76 Training Loss :0.13227684795856476 Test Loss:0.1460409015417099\n",
      "Epoch 77 Training Loss :0.13226857781410217 Test Loss:0.14603199064731598\n",
      "Epoch 78 Training Loss :0.13226038217544556 Test Loss:0.14602291584014893\n",
      "Epoch 79 Training Loss :0.13225223124027252 Test Loss:0.14601370692253113\n",
      "Epoch 80 Training Loss :0.13224412500858307 Test Loss:0.14600437879562378\n",
      "Epoch 81 Training Loss :0.13223609328269958 Test Loss:0.14599494636058807\n",
      "Epoch 82 Training Loss :0.1322280764579773 Test Loss:0.1459854543209076\n",
      "Epoch 83 Training Loss :0.1322200894355774 Test Loss:0.14597587287425995\n",
      "Epoch 84 Training Loss :0.13221216201782227 Test Loss:0.1459662765264511\n",
      "Epoch 85 Training Loss :0.13220424950122833 Test Loss:0.14595665037631989\n",
      "Epoch 86 Training Loss :0.1321963667869568 Test Loss:0.14594700932502747\n",
      "Epoch 87 Training Loss :0.13218852877616882 Test Loss:0.14593735337257385\n",
      "Epoch 88 Training Loss :0.13218070566654205 Test Loss:0.14592768251895905\n",
      "Epoch 89 Training Loss :0.13217292726039886 Test Loss:0.14591801166534424\n",
      "Epoch 90 Training Loss :0.13216517865657806 Test Loss:0.14590835571289062\n",
      "Epoch 91 Training Loss :0.13215743005275726 Test Loss:0.145898699760437\n",
      "Epoch 92 Training Loss :0.13214975595474243 Test Loss:0.1458890587091446\n",
      "Epoch 93 Training Loss :0.1321420818567276 Test Loss:0.14587943255901337\n",
      "Epoch 94 Training Loss :0.13213443756103516 Test Loss:0.14586983621120453\n",
      "Epoch 95 Training Loss :0.1321268230676651 Test Loss:0.14586026966571808\n",
      "Epoch 96 Training Loss :0.13211923837661743 Test Loss:0.14585071802139282\n",
      "Epoch 97 Training Loss :0.13211168348789215 Test Loss:0.14584119617938995\n",
      "Epoch 98 Training Loss :0.13210417330265045 Test Loss:0.14583168923854828\n",
      "Epoch 99 Training Loss :0.13209666311740875 Test Loss:0.14582225680351257\n",
      "Epoch 100 Training Loss :0.13208918273448944 Test Loss:0.14581279456615448\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "simpleNNmodel = SimpleNet()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer = optim.SGD(simpleNNmodel.parameters(), lr=0.01)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    simpleNNmodel.train()\n",
    "    \n",
    "    y_train_output = simpleNNmodel(X_train)\n",
    "    y_test_output = simpleNNmodel(X_test)\n",
    "    loss = simpleNNmodel.loss_criterion(y_train_output,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    validation_loss = simpleNNmodel.loss_criterion(y_test_output,y_test)\n",
    "    print('Epoch {} Training Loss :{} Test Loss:{}'.format((epoch+1),loss,validation_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
